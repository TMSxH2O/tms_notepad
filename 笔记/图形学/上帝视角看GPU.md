
> [!quote] 学习参考
> [上帝视角看GPU（1）：图形流水线基础_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1P44y1V7bu/)

# 1.GPU管线发展

## 1.1.早期（2000年代）

GPU 出现的初衷，是为了可以有专用于并行处理的简单逻辑。因此，才出现了可编程的着色器单元，**像素着色器**，Pixel Shader，针对图像的处理器。

**光栅化**，Rasterizer，为了更加灵活地处理，传入图元（点、三角形、四边形）得到它们在屏幕上覆盖的像素，这个过程就是光栅化。额外需要补充的是，光栅化内部通常还包含了差值处理。计算逻辑固定，通常是直接由硬件直接实现。

**输出合并**，Output Merger，在PS输出的像素如何覆盖和保留，这个步骤就是输出合并。使用深度信息或是模板，判断覆盖或保留像素。

这里的图元输入，通常是由一组顶点组成，顶点组成图元后，裁剪掉超出屏幕的图元，再送到光栅化进行处理。**图元组装单元**，Primitive Assembler，计算逻辑固定，通常是设计为固定的流水线单元。

更进一步，需求进一步发展，出现了希望对顶点信息进行进一步处理的需求，最初还只是为了进行简单的MVP矩阵计算，所以最初是设计为固定流水线，但很快就进化成了可编程的着色器单元，**顶点着色器**，Vertex Shader。

顶点着色器可以自由设置输入，为了实现这个功能，引入了 **输入汇编器**，Input Assembler，来组装处顶点着色器的输入数据。

最终，构成了2000年代最常见的GPU管线。

![[GPU-BaseRenderPipeline.png]]

## 1.2.发展-几何着色器

在后续的发展中，发展出新的需求，**顶点着色器** 只能对顶点进行操作，没办法实现对图元进行修改操作，这就引入了 **几何着色器**，Geometry Shader。支持了对图元进行修改，甚至包括了对图元进行切分（单进多出）。<u>同时也因为支持单进多出，无法预测是否出现了多出，GPU无法优化，导致几何着色器的性能不佳。</u>

在 **顶点着色器** 后，新增 **早期组装单元**，Early Primitive Assembler。之后再调用 此处新增的可选流程 **几何着色器**。

![[GPU-RenderPipeline-GeometryShader.png]]

可以选择的几种情况：

 - 【正常执行像素着色器 + 使用几何着色器】走完上图的所有流程，Stream Output 和 Primitive Assembler 之间选择走下面；
 - 【正常执行像素着色器 + 不使用几何着色器】 Early Primitive Assembler 的流程后直接走到 Primitive Assembler；
 - 【提前输出顶点信息 + 使用几何着色器】 在几何着色器后，选择走 Stream Output，直接返回顶点数据；
 - 【提前输出顶点信息 + 不使用几何着色器】Early Primitive Assembler 后直接就会走到 Stream Output；

## 1.3.发展-细分性能优化

由于 **几何着色器** 实现的单进多出，因为无法预知是否出现了多出，GPU无法进行优化，就带来了严重的性能问题。因此，为了实现这里的细分需求，由专门引入了特化处理的阶段 **细分器**，Tessellator。

将细分分为了三个步骤：

1. **外壳着色器**，Hull Shader<br>可编程，指定每个图元如何被细分，指定哪条边需要被细分，被细分为多少段；
2. **细分器**，Tessellator<br>算法实现固定实现；
3. **域着色器**，Domain Shader<br>可编程，负责计算细分后每个顶点的信息；

![[GPU-细分优化-Tessellator.png]]

这三个阶段也是可选的，如果没有实现，就会直接从 Early Primitive Assembler 连接到 Geometry Shader。

## 1.4.计算着色器出现

既然 GPU 很擅长实现一些简单，但大量重复的并行计算。在这之前，比较常见的做法是，绘制一个覆盖整个屏幕空间的三角形，在 **顶点着色器** 内实现计算。这种方向叫做 **GPU通用计算**，GPGPU。

但这种方式的弊端就是必须开发了解图形流水线，提高了门槛。

这样的需求进一步发展，催生出了硬件支持的 **计算着色器**，Compute Shader。可以任意读取任意写入，不再需要图形流水线的专用计算单元。

## 1.5.未来-网格着色器

从前面的发展也可以看出，这里的图形流水线，一直到 Primitive Assembler 之前，本质上就是把几何数据，改变换变换，该拆开拆开，最后送入光栅化阶段处理。但它们都无法脱离输入的几何数据，要渲染更复杂的物体，就必须输入更复杂的数据。

为了打破这个现状，就必须让 GPU 只依靠少量的输入数据，自动生成大量复杂的数据。

**计算着色器** 的任意读写确实可以实现这样的需求，但它的输出无法连接到 **光栅化处理器**。

这样的需求，催生了 **扩展着色器** （翻译还不统一），Amplification Shader 和 **网格着色器**，Mesh Shader。**扩展着色器** 负责指定执行多少次 **网格着色器**；**网格着色器** 负责产生几何体。

此时渲染的单元不再是以前的图元（点、线、三角形、四边形），而是一小块网格，叫做 **Meshlet**。当 Meshlet 传入给 **扩展着色器**，它会决定 Meshlet 是否需要继续进行处理，如果要的话，就把它往下送到 **网格着色器**，产生带有丰富细节的一堆图元。

![[GPU-MeshShader.png]]
